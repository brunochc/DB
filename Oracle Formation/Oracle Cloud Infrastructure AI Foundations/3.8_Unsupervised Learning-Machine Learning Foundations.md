# Unsupervised Learning
In this lesson, we will learn about unsupervised machine learning. Unsupervised machine learning is a type of machine learning where there are no labeled outputs. The algorithm learns the patterns and relationships in the data and groups, similar data items.

In unsupervised machine learning, patterns in the data are explored without being explicitly told what to look for. For example, if you give a set of different colored LEGO pieces to a child and ask them to the pieces, they may group the LEGO pieces based on any patterns they observe. These could be groups of the same color, size, or type.

Similarly, in unsupervised learning, we group unlabeled data sets. One more example could be, say, imagine you have a basket of various fruits, say apples, bananas, and oranges, and your task is to group these fruits based on their similarities. You observe that some fruits around and red, while others are elongated and yellow. Without being told explicitly, you decide to group the round and red fruits together as one cluster, and the elongated and yellow fruits as another cluster. There you go, you have just performed an unsupervised learning task.

Clustering is a method of grouping data items based on similarities. Within a cluster, the data items are more similar than the items outside the cluster. If some data items do not fall within any cluster, these data items are deemed as outlier points. For example, grapes do have a different shape, size, and color as of apple, pears, and strawberry, and hence could be an outlier.

Having seen what clustering is, let us explore some of its important use cases. The first use case of unsupervised machine learning is market segmentation. In market segmentation, one example is providing the purchasing details of an online shop to a clustering algorithm. Based on the items purchased and purchasing behavior, the clustering algorithm can identify customers based on the similarity between the products purchased. For example, customers with a particular age group who by protein diet products can be shown in advertisement of sports-related products.

The second use case is on outlier analysis. One typical example for outlier analysis is to provide credit card purchase data for clustering. Fraudulent transactions can be detected by a bank by using outliers. In some transaction amounts are too high or recurring, it signifies an outlier.

The third use case is recommendation systems. An example for recommendation systems is to provide users movie viewing history as input to a clustering algorithm. It clusters users based on the type or rating of movies they have watched. The output helps to provide personalized movie recommendations to users, for example, Netflix. The same applies for music recommendations also.

Let us explore the steps involved in unsupervised machine learning. Before that, we need to understand the concept of similarity. Similarity is how close two data points are to each other, and is a value between 0 and 1. Similarity between objects decide which cluster they will fall into, and hence, important for clustering.

Now suppose from a basket of fruits we need to identify similar fruits. We can do it, say, based on color, then apple and cherry are similar to each other based on color. More the similarity between objects, the closer is the value to 1. So for apple and cherry, in this case, similarity would have a value closer to one.

There are various types of similarity measures used in clustering. Let us look at the steps involved in supervised learning to see how similarity metrics are used. Just like supervised learning, unsupervised learning also follows a workflow to cluster. The data, for example, the fruits data, the following steps are followed.

Prepare the data while preparing the data. The basic preprocessing steps, like removing missing values, normalizing the data, and feature scaling are performed. Create similarity matrix. The choice on which similarity matrix to use depends on the nature of the data, and the specific clustering algorithm being used.

Some common similarity metrics which are frequently used are Euclidean distance metric, Manhattan distance metric, cosine similarity matrix, and Jaccard similarity matrix run the clustering algorithm. Clustering algorithms use similarity matrix to cluster the data. The different types of clustering algorithms are partition-based, hierarchical-based, density-based and distribution-based.

Interpret the results and adjust your clustering. Checking the quality of your clustering output is iterative and exploratory. Because there is no labeled output, clustering lacks the ground truth that can verify the output. Verify the results against expectations at the cluster level and the example level. Improving the result requires iteratively experimenting, with the previous steps to see how they affect the clustering. Thanks for watching. 