# Supervised Learning - Regression
Hello, and welcome to this lesson on supervised learning. In this lesson, our focus will be on linear regression. Supervised learning is a machine learning model that learns from labeled data. The model learns the mapping between the input and the output. Let us talk about some typical applications that use a supervised learning model.

As a house price predictor model, we input house size in square feet and model predicts the price of a house. Suppose we need to develop a machine learning model for detecting cancer, the input to the model would be the person's medical details. The output would be whether the tumor is malignant or not.

If a machine learning model is developed for sentiment analysis, the input to the models would be customer reviews for products. The output would be positive, negative, or neutral sentiment labels. If a machine learning model is built for stock price prediction, the inputs would be the opening price, closing price, and volume traded. The output would be the price of the stock. Now let us explore an example to see how the supervised training works.

In supervised learning, the mapping between the input and output is a fundamental concept. It involves teaching a model to learn the relationship between input data and corresponding output or target values. Supervised learning is similar to a teacher teaching student. The model is trained with the past outcomes, and it learns the relationship or mapping between the input and output.

In supervised machine learning model, the outputs can be either categorical or continuous. When the output is continuous, we use regression. And when the output is categorical, we use classification. We will discuss regression and how it is used to predict the housing prices given the house size in square feet as input.

Let us see an example of house price prediction. In this scenario, we want to predict the price of a house based on a single feature, which is the size of the house in square feet. The table shows the data of house size in square feet and price in dollars. The price of the house is dependent on the size of the house, so the price is a dependent feature and house size is an independent feature.

The independent and dependent features are also called input and output. The input feature here is house size and the output label is price. The single row entry of input and output is a single training example or a tuple. This table is the training data set, which will be used for building a machine learning model.

The input and output is plotted in a scatter plot, and this visualization helps in understanding the relationship between them. The graph shows that when the size of the house increases, the price also increases. If we fit a straight line that passes through these points, we can use this line for predicting the price of a house given its size.

See for example, we want to find the price of a property with size as 1,100. We can just find out the corresponding value from the scatter plot if we know the line passing through the points. Here, the relationship between house size and price is represented as a line.

The slope and the bias of a line allows us to position the line to accommodate most of the data points. By changing the bias, we can move the line up and down. And by changing the slope, the line can be tilted upwards or downwards. We arrive at the best fitting line by adjusting slope and bias iteratively.

The equation for this function is given by f of x equal to w multiplied by x plus b, where is the slope of the line in b is the y-intercept. The slope in this case is the rate of change of house price with respect to the house size.

Machine learning algorithm, linear regression in this case, adjusts the positioning of the line by changing the values of the weight and bias. This is done so that the difference between the actual and the predicted value is reduced. The difference between the predicted and actual value is called as error.

Loss is the penalty for a bad prediction. If the model's prediction is perfect, the loss is zero. Otherwise the loss is high. One of the ways to calculate loss is to take a difference between predicted and actual value, and square it. The algorithm iteratively adjusts the weights and bias to minimize the squared loss. Once we arrive at the optimal value of the weight and bias, the model can be used for prediction.

To summarize, we train a regression model by giving input and output value pairs, which we call as data set. The algorithm learns a function f, which is the mapping function. This represents a trained model. This function is used for prediction. If we give house size as input to the trained model, the learned function can predict a house price. Thanks for watching.

